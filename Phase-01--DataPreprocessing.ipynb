{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d89b02f0",
   "metadata": {},
   "source": [
    "# Data Pre-Processing [Cleaning + Feature Engineering] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f2628e",
   "metadata": {},
   "source": [
    "## Knowing the features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb1a537",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85d2e0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8876c8",
   "metadata": {},
   "source": [
    "### Setting up paths to csv files / datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b03c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV-01-12\n",
    "path_DrDoS_DNS = \"../CICDDoS-2019/CSV-01-12/01-12/DrDoS_DNS.csv\"\n",
    "path_DrDoS_MSSQL = \"../CICDDoS-2019/CSV-01-12/01-12/DrDoS_MSSQL.csv\"\n",
    "path_DrDoS_LDAP = \"../CICDDoS-2019/CSV-01-12/01-12/DrDoS_LDAP.csv\"\n",
    "path_DrDoS_NTP = \"../CICDDoS-2019/CSV-01-12/01-12/DrDoS_NTP.csv\"\n",
    "path_DrDoS_NetBIOS = \"../CICDDoS-2019/CSV-01-12/01-12/DrDoS_NetBIOS.csv\"\n",
    "path_DrDoS_SNMP = \"../CICDDoS-2019/CSV-01-12/01-12/DrDoS_SNMP.csv\"\n",
    "path_DrDoS_SSDP = \"../CICDDoS-2019/CSV-01-12/01-12/DrDoS_SSDP.csv\"\n",
    "path_DrDoS_UDP = \"../CICDDoS-2019/CSV-01-12/01-12/DrDoS_UDP.csv\"\n",
    "path_Syn = \"../CICDDoS-2019/CSV-01-12/01-12/Syn.csv\"\n",
    "path_TFTP = \"../CICDDoS-2019/CSV-01-12/01-12/TFTP.csv\"\n",
    "path_UDPLag = \"../CICDDoS-2019/CSV-01-12/01-12/UDPLag.csv\"\n",
    "\n",
    "# CSV-03-11\n",
    "path__LDAP = \"../CICDDoS-2019/CSV-03-11/03-11/LDAP.csv\"\n",
    "path__MSSQL = \"../CICDDoS-2019/CSV-03-11/03-11/MSSQL.csv\"\n",
    "path__NetBIOS = \"../CICDDoS-2019/CSV-03-11/03-11/NetBIOS.csv\"\n",
    "path__Portmap = \"../CICDDoS-2019/CSV-03-11/03-11/Portmap.csv\"\n",
    "path__Syn = \"../CICDDoS-2019/CSV-03-11/03-11/Syn.csv\"\n",
    "path__UDP = \"../CICDDoS-2019/CSV-03-11/03-11/UDP.csv\"\n",
    "path__UDPLag = \"../CICDDoS-2019/CSV-03-11/03-11/UDPLag.csv\"\n",
    "\n",
    "paths = [path_DrDoS_DNS, path_DrDoS_MSSQL, path_DrDoS_LDAP, path_DrDoS_NTP, path_DrDoS_NetBIOS, path_DrDoS_SNMP,\n",
    "         path_DrDoS_SSDP, path_DrDoS_UDP, path_Syn, path_TFTP, path_UDPLag, path__LDAP, path__MSSQL, path__NetBIOS, path__Portmap, path__Syn, path__UDP, path__UDPLag]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537f1902",
   "metadata": {},
   "source": [
    "### Making a large csv file workable in our machine and returning the results as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58096b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readALargeCSVFileAndGetResultAsDF(path):\n",
    "    mylist = []\n",
    "\n",
    "    for chunk in pd.read_csv(path, chunksize=20000, low_memory=False):\n",
    "        mylist.append(chunk)\n",
    "\n",
    "    big_data = pd.concat(mylist, axis=0)\n",
    "    del mylist\n",
    "    return big_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e471b3",
   "metadata": {},
   "source": [
    "### Function that gives us a complete rundown about which features are crossing the threshold mark of having zeros[0] ... So that we can come to a decision for eliminating those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d48040",
   "metadata": {},
   "outputs": [],
   "source": [
    "featureSelectedBasedOn0Results = []\n",
    "\n",
    "def giveInfoAboutFile(path, threshHoldPercentage, showPercentage):\n",
    "    \n",
    "    if path == path_TFTP:\n",
    "        df = readALargeCSVFileAndGetResultAsDF(path)\n",
    "    else:\n",
    "        df = pd.read_csv(path, low_memory=False)\n",
    "    \n",
    "    df = df.dropna()\n",
    "    \n",
    "    totalCols = df.shape[1]\n",
    "    totalRows = len(df)\n",
    "    unnecessaryFeatureCount = 0\n",
    "    unnecessaryFeatureNames = []\n",
    "\n",
    "    for column in df:\n",
    "        zerosInCol = (df[column] == 0).sum()\n",
    "        if zerosInCol != 0:\n",
    "            percentageOfZerosInRow = ((zerosInCol*100)/totalRows)\n",
    "            \n",
    "            if showPercentage:\n",
    "                print(column , \" - \", zerosInCol, \" - \", percentageOfZerosInRow)\n",
    "\n",
    "            if percentageOfZerosInRow > threshHoldPercentage:\n",
    "                unnecessaryFeatureNames.append(column)\n",
    "                unnecessaryFeatureCount = unnecessaryFeatureCount + 1\n",
    "                \n",
    "    print()\n",
    "        \n",
    "    unitResult = [path, threshHoldPercentage, unnecessaryFeatureNames]\n",
    "    \n",
    "    featureSelectedBasedOn0Results.append(unitResult)\n",
    "    \n",
    "    print()\n",
    "    print(\"In\", path, \"Total features having more than \", threshHoldPercentage,\n",
    "          \"% zero are - \", unnecessaryFeatureCount, \"out of \", totalCols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12a1af8",
   "metadata": {},
   "source": [
    "### Running the {{giveInfoAboutFile}} function for all the csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcd987c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    giveInfoAboutFile(path, 99, False)\n",
    "    \n",
    "featureSelectedBasedOn0Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c05366",
   "metadata": {},
   "source": [
    "### Seeing the feature counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe0afcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for case in featureSelectedBasedOn0Results:\n",
    "    print(case[0], \"---\", len(case[2]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6ece2b",
   "metadata": {},
   "source": [
    "## \n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a255c99",
   "metadata": {},
   "source": [
    "## Two approaches for DATA CLEANING...\n",
    "\n",
    "**1. As the feature counts are not the same so have to intersect them and after getting a small subset [features that are 0 across all the files] and dropping those features... Merging files will be easy**\n",
    "<br/>\n",
    "<br/>\n",
    "**2. Drop the features as per the result...  Merging all the files will be difficult as files will be then with different features**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfd60f0",
   "metadata": {},
   "source": [
    "### Function that will save the new csv to a proper destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b46381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveNewCSV(path, newPathDir, eliminatingFeatures, fileNewName):\n",
    "    \n",
    "    # read files\n",
    "    if path == path_TFTP:\n",
    "        df = readALargeCSVFileAndGetResultAsDF(path)\n",
    "    else:\n",
    "        df = pd.read_csv(path, low_memory=False)\n",
    "        \n",
    "    # remove the cols\n",
    "    df.drop(eliminatingFeatures, axis=1, inplace=True)\n",
    "\n",
    "    # save to directory\n",
    "    df.to_csv(newPathDir + fileNewName)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d0f2cd",
   "metadata": {},
   "source": [
    "### Approach 01 [intersecting features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598aece4",
   "metadata": {},
   "source": [
    "#### Find the intersecting feature sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a49957",
   "metadata": {},
   "source": [
    "**This piece of code is for getting intersecting elements between two lists**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa72ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    return lst3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3d9009",
   "metadata": {},
   "source": [
    "**Running for the intersecting elements... These elements are giving at least threshold percentage of 0 in all the csv files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a53156",
   "metadata": {},
   "outputs": [],
   "source": [
    "eliminatingFeaturesBasedOnIntersection = []\n",
    "for featureSet in featureSelectedBasedOn0Results:\n",
    "    if len(eliminatingFeaturesBasedOnIntersection) == 0:\n",
    "        eliminatingFeaturesBasedOnIntersection = featureSet[2]\n",
    "    else:\n",
    "        eliminatingFeaturesBasedOnIntersection = intersection(\n",
    "            eliminatingFeaturesBasedOnIntersection, featureSet[2])\n",
    "print(len(eliminatingFeaturesBasedOnIntersection))\n",
    "print(eliminatingFeaturesBasedOnIntersection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd76e733",
   "metadata": {},
   "source": [
    "#### Dropping the features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e2719b",
   "metadata": {},
   "source": [
    "**run code for all the files**\n",
    "**saving to '../FinalSmallDatasets/Intersecting Feature Elimination/' directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62975d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "newDir = '../FinalSmallDatasets/Intersecting Feature Elimination/'\n",
    "\n",
    "for path in paths:\n",
    "    \n",
    "    # make the new name\n",
    "    name = path.split('/')\n",
    "    name = name[len(name)-2] + '__' + name[len(name)-1]\n",
    "    \n",
    "    saveNewCSV(path, newDir, eliminatingFeaturesBasedOnIntersection, name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25edeb2",
   "metadata": {},
   "source": [
    "### Approach 02 [individual features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6e41f3",
   "metadata": {},
   "source": [
    "#### Dropping the features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9ff7ce",
   "metadata": {},
   "source": [
    "**run code for all the files**\n",
    "**saving to '../FinalSmallDatasets/Individual Elimination/' directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62975d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "newDir = '../FinalSmallDatasets/Individual Elimination/'\n",
    "\n",
    "for eliminationInfo in featureSelectedBasedOn0Results:\n",
    "    \n",
    "    path = eliminationInfo[0]\n",
    "    eliminatingFeaturesBasedOnIndividual = eliminationInfo[2]\n",
    "    \n",
    "    # make the new name\n",
    "    name = path.split('/')\n",
    "    name = name[len(name)-2] + '__' + name[len(name)-1]\n",
    "    \n",
    "    saveNewCSV(path, newDir, eliminatingFeaturesBasedOnIndividual, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6ece2b",
   "metadata": {},
   "source": [
    "## \n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776c7b2d",
   "metadata": {},
   "source": [
    "## Taking Less Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbb135c",
   "metadata": {},
   "source": [
    "### Get files paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e099b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropped by intersecting features files paths\n",
    "\n",
    "path_dropped_intersection_01_12__DrDoS_DNS = '../FinalSmallDatasets/Intersecting Feature Elimination/01-12__DrDoS_DNS.csv'\n",
    "path_dropped_intersection_01_12__DrDoS_LDAP = '../FinalSmallDatasets/Intersecting Feature Elimination/01-12__DrDoS_LDAP.csv'\n",
    "path_dropped_intersection_01_12__DrDoS_MSSQL = '../FinalSmallDatasets/Intersecting Feature Elimination/01-12__DrDoS_MSSQL.csv'\n",
    "path_dropped_intersection_01_12__DrDoS_NetBIOS = '../FinalSmallDatasets/Intersecting Feature Elimination/01-12__DrDoS_NetBIOS.csv'\n",
    "path_dropped_intersection_01_12__DrDoS_NTP = '../FinalSmallDatasets/Intersecting Feature Elimination/01-12__DrDoS_NTP.csv'\n",
    "path_dropped_intersection_01_12__DrDoS_SNMP = '../FinalSmallDatasets/Intersecting Feature Elimination/01-12__DrDoS_SNMP.csv'\n",
    "path_dropped_intersection_01_12__DrDoS_SSDP = '../FinalSmallDatasets/Intersecting Feature Elimination/01-12__DrDoS_SSDP.csv'\n",
    "path_dropped_intersection_01_12__DrDoS_UDP = '../FinalSmallDatasets/Intersecting Feature Elimination/01-12__DrDoS_UDP.csv'\n",
    "path_dropped_intersection_01_12__Syn = '../FinalSmallDatasets/Intersecting Feature Elimination/01-12__Syn.csv'\n",
    "path_dropped_intersection_01_12__TFTP = '../FinalSmallDatasets/Intersecting Feature Elimination/01-12__TFTP.csv'\n",
    "path_dropped_intersection_01_12__UDPLag = '../FinalSmallDatasets/Intersecting Feature Elimination/01-12__UDPLag.csv'\n",
    "path_dropped_intersection_03_11__LDAP = '../FinalSmallDatasets/Intersecting Feature Elimination/03-11__LDAP.csv'\n",
    "path_dropped_intersection_03_11__MSSQL = '../FinalSmallDatasets/Intersecting Feature Elimination/03-11__MSSQL.csv'\n",
    "path_dropped_intersection_03_11__NetBIOS = '../FinalSmallDatasets/Intersecting Feature Elimination/03-11__NetBIOS.csv'\n",
    "path_dropped_intersection_03_11__Portmap = '../FinalSmallDatasets/Intersecting Feature Elimination/03-11__Portmap.csv'\n",
    "path_dropped_intersection_03_11__Syn = '../FinalSmallDatasets/Intersecting Feature Elimination/03-11__Syn.csv'\n",
    "path_dropped_intersection_03_11__UDP = '../FinalSmallDatasets/Intersecting Feature Elimination/03-11__UDP.csv'\n",
    "path_dropped_intersection_03_11__UDPLag = '../FinalSmallDatasets/Intersecting Feature Elimination/03-11__UDPLag.csv'\n",
    "\n",
    "pathsForIntersectingDroppedFiles = [path_dropped_intersection_01_12__DrDoS_DNS, path_dropped_intersection_01_12__DrDoS_LDAP, path_dropped_intersection_01_12__DrDoS_MSSQL, path_dropped_intersection_01_12__DrDoS_NetBIOS, path_dropped_intersection_01_12__DrDoS_NTP, path_dropped_intersection_01_12__DrDoS_SNMP, path_dropped_intersection_01_12__DrDoS_SSDP, path_dropped_intersection_01_12__DrDoS_UDP, path_dropped_intersection_01_12__Syn, path_dropped_intersection_01_12__TFTP, path_dropped_intersection_01_12__UDPLag, path_dropped_intersection_03_11__LDAP, path_dropped_intersection_03_11__MSSQL, path_dropped_intersection_03_11__NetBIOS, path_dropped_intersection_03_11__Portmap, path_dropped_intersection_03_11__Syn, path_dropped_intersection_03_11__UDP, path_dropped_intersection_03_11__UDPLag]\n",
    "\n",
    "\n",
    "\n",
    "# dropped by individual features files paths\n",
    "\n",
    "path_dropped_individual_01_12__DrDoS_DNS = '../FinalSmallDatasets/Individual Elimination/01-12__DrDoS_DNS.csv'\n",
    "path_dropped_individual_01_12__DrDoS_LDAP = '../FinalSmallDatasets/Individual Elimination/01-12__DrDoS_LDAP.csv'\n",
    "path_dropped_individual_01_12__DrDoS_MSSQL = '../FinalSmallDatasets/Individual Elimination/01-12__DrDoS_MSSQL.csv'\n",
    "path_dropped_individual_01_12__DrDoS_NetBIOS = '../FinalSmallDatasets/Individual Elimination/01-12__DrDoS_NetBIOS.csv'\n",
    "path_dropped_individual_01_12__DrDoS_NTP = '../FinalSmallDatasets/Individual Elimination/01-12__DrDoS_NTP.csv'\n",
    "path_dropped_individual_01_12__DrDoS_SNMP = '../FinalSmallDatasets/Individual Elimination/01-12__DrDoS_SNMP.csv'\n",
    "path_dropped_individual_01_12__DrDoS_SSDP = '../FinalSmallDatasets/Individual Elimination/01-12__DrDoS_SSDP.csv'\n",
    "path_dropped_individual_01_12__DrDoS_UDP = '../FinalSmallDatasets/Individual Elimination/01-12__DrDoS_UDP.csv'\n",
    "path_dropped_individual_01_12__Syn = '../FinalSmallDatasets/Individual Elimination/01-12__Syn.csv'\n",
    "path_dropped_individual_01_12__TFTP = '../FinalSmallDatasets/Individual Elimination/01-12__TFTP.csv'\n",
    "path_dropped_individual_01_12__UDPLag = '../FinalSmallDatasets/Individual Elimination/01-12__UDPLag.csv'\n",
    "path_dropped_individual_03_11__LDAP = '../FinalSmallDatasets/Individual Elimination/03-11__LDAP.csv'\n",
    "path_dropped_individual_03_11__MSSQL = '../FinalSmallDatasets/Individual Elimination/03-11__MSSQL.csv'\n",
    "path_dropped_individual_03_11__NetBIOS = '../FinalSmallDatasets/Individual Elimination/03-11__NetBIOS.csv'\n",
    "path_dropped_individual_03_11__Portmap = '../FinalSmallDatasets/Individual Elimination/03-11__Portmap.csv'\n",
    "path_dropped_individual_03_11__Syn = '../FinalSmallDatasets/Individual Elimination/03-11__Syn.csv'\n",
    "path_dropped_individual_03_11__UDP = '../FinalSmallDatasets/Individual Elimination/03-11__UDP.csv'\n",
    "path_dropped_individual_03_11__UDPLag = '../FinalSmallDatasets/Individual Elimination/03-11__UDPLag.csv'\n",
    "\n",
    "pathsForIndividualDroppedFiles = [path_dropped_individual_01_12__DrDoS_DNS, path_dropped_individual_01_12__DrDoS_LDAP, path_dropped_individual_01_12__DrDoS_MSSQL, path_dropped_individual_01_12__DrDoS_NetBIOS, path_dropped_individual_01_12__DrDoS_NTP, path_dropped_individual_01_12__DrDoS_SNMP, path_dropped_individual_01_12__DrDoS_SSDP, path_dropped_individual_01_12__DrDoS_UDP,\n",
    "                                    path_dropped_individual_01_12__Syn, path_dropped_individual_01_12__TFTP, path_dropped_individual_01_12__UDPLag, path_dropped_individual_03_11__LDAP, path_dropped_individual_03_11__MSSQL, path_dropped_individual_03_11__NetBIOS, path_dropped_individual_03_11__Portmap, path_dropped_individual_03_11__Syn, path_dropped_individual_03_11__UDP, path_dropped_individual_03_11__UDPLag]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a16fe8",
   "metadata": {},
   "source": [
    "### Function for Random Selection Per File & Save as new CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea115d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomSelectionAndSave(path, newDir, sampleSize, name):\n",
    "    \n",
    "    if path == path_TFTP:\n",
    "        df = readALargeCSVFileAndGetResultAsDF(path)\n",
    "    else:\n",
    "        df = pd.read_csv(path, low_memory=False)\n",
    "        \n",
    "    df.dropna(inplace=True)\n",
    "    # number of records in file (excludes header)\n",
    "    totalFileRowCount = sum(1 for line in open(path)) - 1\n",
    "    # the 0-indexed header will not be included in the skip list\n",
    "    skip = sorted(random.sample(range(1, totalFileRowCount+1), totalFileRowCount-sampleSize))\n",
    "    df = pd.read_csv(path, skiprows=skip, low_memory=False)\n",
    "    \n",
    "    # df = df.sample(n=sampleSize)\n",
    "    \n",
    "    df.to_csv(newDir + name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497bd95d",
   "metadata": {},
   "source": [
    "### 10k per file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653e54ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleSize = 10000\n",
    "\n",
    "# intersecting ones\n",
    "newDirIntersecting = '../FinalSmallDatasets/Intersecting Feature Elimination/sets-of-10k/'\n",
    "\n",
    "for path in pathsForIntersectingDroppedFiles:\n",
    "\n",
    "    # make the new name\n",
    "    name = path.split('/')\n",
    "    name = (name[len(name)-2] + '__' + name[len(name)-1]).replace(\" \", \"\")\n",
    "\n",
    "    randomSelectionAndSave(path, newDirIntersecting, sampleSize, name)\n",
    "\n",
    "# individual ones\n",
    "newDirIndividual = '../FinalSmallDatasets/Individual Elimination/sets-of-10k/'\n",
    "\n",
    "for path in pathsForIndividualDroppedFiles:\n",
    "\n",
    "    # make the new name\n",
    "    name = path.split('/')\n",
    "    name = (name[len(name)-2] + '__' + name[len(name)-1]).replace(\" \", \"\")\n",
    "\n",
    "    randomSelectionAndSave(path, newDirIndividual, sampleSize, name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e8f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleSize = 10000\n",
    "\n",
    "newDirIntersecting = '../FinalSmallDatasets/Individual Elimination/sets-of-10k/'\n",
    "path = path_dropped_individual_01_12__TFTP\n",
    "name = path.split('/')\n",
    "name = (name[len(name)-2] + '__' + name[len(name)-1]).replace(\" \", \"\")\n",
    "\n",
    "name\n",
    "\n",
    "df = readALargeCSVFileAndGetResultAsDF(path)\n",
    "df\n",
    "# randomSelectionAndSave(path, newDirIntersecting, sampleSize, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136d572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91ee42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5861ede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0fdd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleSize = 10000\n",
    "df = df.sample(n=sampleSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f79596",
   "metadata": {},
   "outputs": [],
   "source": [
    "newDirIndividual = '../FinalSmallDatasets/Individual Elimination/sets-of-10k/'\n",
    "path = path_dropped_individual_01_12__TFTP\n",
    "name = path.split('/')\n",
    "name = (name[len(name)-2] + '__' + name[len(name)-1]).replace(\" \", \"\")\n",
    "\n",
    "df.to_csv(newDirIndividual + name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df967374",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../FinalSmallDatasets/Individual Elimination/sets-of-10k/IndividualElimination__03-11__LDAP.csv', low_memory=False)\n",
    "\n",
    "df.isna().sum().sum()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f05f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleSize = 10000\n",
    "\n",
    "newDirIndividual = '../FinalSmallDatasets/Individual Elimination/sets-of-10k/'\n",
    "path = path_dropped_individual_01_12__TFTP\n",
    "name = path.split('/')\n",
    "name = (name[len(name)-2] + '__' + name[len(name)-1]).replace(\" \", \"\")\n",
    "\n",
    "randomSelectionAndSave(path, newDirIndividual, sampleSize, name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a16fe8",
   "metadata": {},
   "source": [
    "### Function for Random Selection Considering All Files & Save as new CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cea115d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomSelectionOverAllFileAndSave(pathArray, newDir, sampleSize, name):\n",
    "    \n",
    "    perSampleSize = int(float(sampleSize / len(pathArray)))\n",
    "    \n",
    "    counter = 0\n",
    "    randomIndex = random.randint(0, len(pathArray) - 1)\n",
    "    \n",
    "    bigDf = pd.DataFrame()\n",
    "\n",
    "    for path in pathArray:\n",
    "        \n",
    "        if counter == randomIndex:\n",
    "            perSampleSize = abs(sampleSize - (len(pathArray) * perSampleSize))\n",
    "        \n",
    "        \n",
    "        df = pd.read_csv(path, low_memory=False)\n",
    "            \n",
    "        # # number of records in file (excludes header)\n",
    "        # totalFileRowCount = sum(1 for line in open(path)) - 1\n",
    "        # # the 0-indexed header will not be included in the skip list\n",
    "        # skip = sorted(random.sample(range(1, totalFileRowCount+1),\n",
    "        #                 totalFileRowCount-perSampleSize))\n",
    "        # df = pd.read_csv(path, skiprows=skip, low_memory=False)\n",
    "\n",
    "        df = df.sample(n=perSampleSize)\n",
    "\n",
    "        bigDf = bigDf.append(df)\n",
    "        \n",
    "        counter = counter + 1\n",
    "    \n",
    "    bigDf.to_csv(newDir + name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0e022a",
   "metadata": {},
   "source": [
    "### Overall 10k file [based on intersection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8b1d9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_17580\\2348875271.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(df)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_17580\\2348875271.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(df)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_17580\\2348875271.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(df)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_17580\\2348875271.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(df)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_17580\\2348875271.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(df)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_17580\\2348875271.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(df)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_17580\\2348875271.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(df)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_17580\\2348875271.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(df)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_17580\\2348875271.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(df)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_17580\\2348875271.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(df)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_17580\\2348875271.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(df)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_17580\\2348875271.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(df)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_17580\\2348875271.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(df)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_17580\\2348875271.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(df)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_17580\\2348875271.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(df)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_17580\\2348875271.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(df)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_17580\\2348875271.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(df)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_17580\\2348875271.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(df)\n"
     ]
    }
   ],
   "source": [
    "newDirForRandomSelectionOverAll = '../FinalSmallDatasets/Intersecting Feature Elimination/overall-10k/'\n",
    "nameForRandomSelectionOverAll = 'data10k.csv'\n",
    "sampleSizeForRandomSelectionOverAll = 10000\n",
    "\n",
    "pathsForIntersectingDroppedAndReducedFiles = [\n",
    "    '../FinalSmallDatasets/Intersecting Feature Elimination/sets-of-10k/IntersectingFeatureElimination__01-12__DrDoS_DNS.csv',\n",
    "    '../FinalSmallDatasets/Intersecting Feature Elimination/sets-of-10k/IntersectingFeatureElimination__01-12__DrDoS_LDAP.csv',\n",
    "    '../FinalSmallDatasets/Intersecting Feature Elimination/sets-of-10k/IntersectingFeatureElimination__01-12__DrDoS_MSSQL.csv',\n",
    "    '../FinalSmallDatasets/Intersecting Feature Elimination/sets-of-10k/IntersectingFeatureElimination__01-12__DrDoS_NetBIOS.csv',\n",
    "    '../FinalSmallDatasets/Intersecting Feature Elimination/sets-of-10k/IntersectingFeatureElimination__01-12__DrDoS_NTP.csv',\n",
    "    '../FinalSmallDatasets/Intersecting Feature Elimination/sets-of-10k/IntersectingFeatureElimination__01-12__DrDoS_SNMP.csv',\n",
    "    '../FinalSmallDatasets/Intersecting Feature Elimination/sets-of-10k/IntersectingFeatureElimination__01-12__DrDoS_SSDP.csv',\n",
    "    '../FinalSmallDatasets/Intersecting Feature Elimination/sets-of-10k/IntersectingFeatureElimination__01-12__DrDoS_UDP.csv',\n",
    "    '../FinalSmallDatasets/Intersecting Feature Elimination/sets-of-10k/IntersectingFeatureElimination__01-12__Syn.csv',\n",
    "    '../FinalSmallDatasets/Intersecting Feature Elimination/sets-of-10k/IntersectingFeatureElimination__01-12__TFTP.csv',\n",
    "    '../FinalSmallDatasets/Intersecting Feature Elimination/sets-of-10k/IntersectingFeatureElimination__01-12__UDPLag.csv',\n",
    "    '../FinalSmallDatasets/Intersecting Feature Elimination/sets-of-10k/IntersectingFeatureElimination__03-11__LDAP.csv',\n",
    "    '../FinalSmallDatasets/Intersecting Feature Elimination/sets-of-10k/IntersectingFeatureElimination__03-11__MSSQL.csv',\n",
    "    '../FinalSmallDatasets/Intersecting Feature Elimination/sets-of-10k/IntersectingFeatureElimination__03-11__NetBIOS.csv',\n",
    "    '../FinalSmallDatasets/Intersecting Feature Elimination/sets-of-10k/IntersectingFeatureElimination__03-11__Portmap.csv',\n",
    "    '../FinalSmallDatasets/Intersecting Feature Elimination/sets-of-10k/IntersectingFeatureElimination__03-11__Syn.csv',\n",
    "    '../FinalSmallDatasets/Intersecting Feature Elimination/sets-of-10k/IntersectingFeatureElimination__03-11__UDP.csv',\n",
    "    '../FinalSmallDatasets/Intersecting Feature Elimination/sets-of-10k/IntersectingFeatureElimination__03-11__UDPLag.csv'\n",
    "]\n",
    "\n",
    "randomSelectionOverAllFileAndSave(pathsForIntersectingDroppedAndReducedFiles, newDirForRandomSelectionOverAll,\n",
    "                                  sampleSizeForRandomSelectionOverAll, nameForRandomSelectionOverAll)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6ece2b",
   "metadata": {},
   "source": [
    "## \n",
    "---\n",
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4452c4265dc4541c23fc3903fb7f31bc4a675511aa78fb8563eb9b54f6c8cb29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
